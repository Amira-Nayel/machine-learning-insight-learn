# -*- coding: utf-8 -*-
"""KNNABCDF2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k3t0eSAMiRxmt8t55RbP2TMH62jgWGPZ
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
# Load the data
final_merged = pd.read_csv('/content/drive/MyDrive/fffffffff (2).csv')

# Drop unnecessary columns
cols_drop = ['Full Name', 'Username', 'Seat No.', 'Time taken', 'userEmail','SA&D Midterm Grade']
df_drop = final_merged.drop(columns=cols_drop)

# Drop rows with missing 'Final SA&D' and 'attention_min'
df_Nulldrop = df_drop.dropna(subset=['Final SA&D', 'attention_min'])

# Define features to scale
features_to_scale = ['grade_and_time', 'arousal_min', 'arousal_max', 'attention_min', 'attention_max',
                     'valence_max', 'valence_min', 'volume_min', 'volume_max', 'arousal', 'attention',
                     'valence', 'volume']


# Select features and labels
X = df_Nulldrop[features_to_scale]

# Define a function to assign letter grades
def assign_letter_grade(grade):
    if grade >= 90:
        return 'A'
    elif grade >= 80:
        return 'B'
    elif grade >= 70:
        return 'C'
    elif grade >= 60:
        return 'D'
    else:
        return 'F'

# Apply the function to the target column
y = df_Nulldrop['Final SA&D'].apply(assign_letter_grade)

# Handle missing values in features
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)

# Initialize the scaler
scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)

# Initialize the KNN model
knn_model = KNeighborsClassifier()

# Define the parameter grid for GridSearchCV
param_grid = {
    'n_neighbors': [3, 5, 7, 9, 11],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

# Initialize GridSearchCV
grid_search = GridSearchCV(knn_model, param_grid, cv=5, verbose=2, n_jobs=-1)

# Fit GridSearchCV
grid_search.fit(X_train_scaled, y_train)

# Get the best estimator
best_knn_model = grid_search.best_estimator_

# Make predictions
y_pred = best_knn_model.predict(X_test_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

# Display the classification report for more detailed metrics
print(classification_report(y_test, y_pred))

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(conf_matrix)

# Visualize the confusion matrix using seaborn
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['A', 'B', 'C', 'D', 'F'], yticklabels=['A', 'B', 'C', 'D', 'F'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()